import numpy as np
import pandas as pd
import os
import cv2
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import classification_report
from tqdm import tqdm

# Hiperparametreler
IMG_SIZE = (224, 224)
BATCH_SIZE = 128
EPOCHS = 50

def load_data(fish_dir):
    labels, paths = [], []
    for dir_name, _, filenames in os.walk(fish_dir):
        for filename in filenames:
            if filename.endswith('.png') and 'GT' not in dir_name:
                labels.append(os.path.basename(dir_name))
                paths.append(os.path.join(dir_name, filename))
    return pd.DataFrame({'path': paths, 'label': labels})

def visualize_sample_data(data):
    plt.figure(figsize=(15, 12))
    for idx, unique_label in enumerate(data['label'].unique()):
        plt.subplot(3, 3, idx + 1)
        sample_img = plt.imread(data[data['label'] == unique_label].iloc[0, 0])
        plt.imshow(sample_img)
        plt.title(unique_label)
        plt.axis('off')
    plt.show()

def preprocess_images(data):
    images, labels = [], []
    main_directory = os.path.dirname(data['path'].iloc[0])  # Ana dizini al

    for label in tqdm(data['label'].unique()):
        dir_path = os.path.join(main_directory, label)

        # Dizin var mı kontrolü
        if not os.path.exists(dir_path):
            print(f"Dizin bulunamadı: {dir_path}")
            continue
        
        for img_file in os.listdir(dir_path):
            if img_file.endswith('.png'):
                img_path = os.path.join(dir_path, img_file)
                img = cv2.imread(img_path)
                if img is not None:
                    img = cv2.resize(img, IMG_SIZE)
                    images.append(img)
                    labels.append(label)

    if len(images) == 0:
        raise ValueError("Hiçbir resim yüklenemedi. Dizin yapısını kontrol edin.")

    return np.array(images), np.array(labels)

def build_model(input_shape, num_classes):
    model = models.Sequential([
        layers.Flatten(input_shape=input_shape),
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.2),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.2),
        layers.Dense(num_classes, activation='softmax')
    ])
    return model

def plot_results(history):
    plt.figure(figsize=(12, 5))

    # Loss chart
    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Loss Graph')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    # Accuracy chart
    plt.subplot(1, 2, 2)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title('Accuracy Graph')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.tight_layout()
    plt.show()

def main():
    fish_dir = '/kaggle/input/a-large-scale-fish-dataset/Fish_Dataset/Fish_Dataset'
    data = load_data(fish_dir)

    # Görsel örneklerin görüntülenmesi
    visualize_sample_data(data)

    # Resimleri yükleme ve ön işleme
    X, y = preprocess_images(data)

    # Veri kümesini eğitim, doğrulama ve test setlerine ayırma
    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=0)
    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=0)

    # OneHot Encoding
    encoder = OneHotEncoder(sparse=False)
    y_train = encoder.fit_transform(y_train.reshape(-1, 1))
    y_val = encoder.transform(y_val.reshape(-1, 1))
    y_test = encoder.transform(y_test.reshape(-1, 1))

    # Modelin oluşturulması
    model = build_model((IMG_SIZE[0], IMG_SIZE[1], 3), y_train.shape[1])
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

    # Modelin eğitilmesi
    datagen = ImageDataGenerator(rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True)
    datagen.fit(X_train)

    history = model.fit(datagen.flow(X_train, y_train, batch_size=BATCH_SIZE), 
                        epochs=EPOCHS, 
                        validation_data=(X_val, y_val),
                        callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)])

    # Sonuçların görselleştirilmesi
    plot_results(history)

    # Test seti ile değerlendirme
    y_pred = model.predict(X_test)
    y_pred_classes = np.argmax(y_pred, axis=1)
    test_labels = encoder.inverse_transform(y_test)
    prediction_labels = encoder.inverse_transform(y_pred)

    print(classification_report(test_labels, prediction_labels))

if __name__ == "__main__":
    main()
